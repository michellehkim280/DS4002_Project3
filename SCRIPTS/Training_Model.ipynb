{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCIeBNWwehwe"
      },
      "outputs": [],
      "source": [
        "# This code block below is to train a U-Net model for semantic segmentation of forested and non-forested areas using satellite images.\n",
        "\n",
        "# Importing necessary packages\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import rasterio\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Defining U-Net Model and adding regularization\n",
        "def unet_model(input_size=(256, 256, 4)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoding Path\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    pool1 = Dropout(0.3)(pool1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    pool2 = Dropout(0.3)(pool2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    pool3 = Dropout(0.3)(pool3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv4)\n",
        "    conv4 = Dropout(0.5)(conv4)\n",
        "\n",
        "    # Decoding Path\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    merge5 = concatenate([conv3, up5], axis=3)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(merge5)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv5)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    merge6 = concatenate([conv2, up6], axis=3)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(merge6)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv6)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    merge7 = concatenate([conv1, up7], axis=3)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(merge7)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(conv7)\n",
        "\n",
        "    conv8 = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv8)\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Loading data and resizing images\n",
        "def load_data(image_paths, mask_paths, target_size=(256, 256)):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for img_path, mask_path in zip(image_paths, mask_paths):\n",
        "        # Loading GeoTIFF images\n",
        "        with rasterio.open(img_path) as src:\n",
        "            image = src.read()\n",
        "            image = np.transpose(image, (1, 2, 0))  # Reorder dimensions to (height, width, channels)\n",
        "            image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)  # Resize image\n",
        "            image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "        # Loading mask\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)  # Resize mask\n",
        "        mask = cv2.threshold(mask, 127, 1, cv2.THRESH_BINARY)[1]  # Binarize mask\n",
        "\n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "\n",
        "    images = np.array(images)\n",
        "    masks = np.array(masks)\n",
        "    masks = np.expand_dims(masks, axis=-1)  # Add channel dimension to masks\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "# Paths to datasets\n",
        "train_image_folder = \"/content/drive/MyDrive/folder/AMAZON-1/Training/image/\"\n",
        "train_mask_folder = \"/content/drive/MyDrive/folder/AMAZON-1/Training/label/\"\n",
        "\n",
        "validation_image_folder = \"/content/drive/MyDrive/folder/AMAZON-1/Validation/images/\"\n",
        "validation_mask_folder = \"/content/drive/MyDrive/folder/AMAZON-1/Validation/masks/\"\n",
        "\n",
        "# Getting all image and mask paths\n",
        "train_image_paths = sorted(glob.glob(train_image_folder + \"/*.tif\"))\n",
        "train_mask_paths = sorted(glob.glob(train_mask_folder + \"/*.tif\"))\n",
        "\n",
        "validation_image_paths = sorted(glob.glob(validation_image_folder + \"/*.tif\"))\n",
        "validation_mask_paths = sorted(glob.glob(validation_mask_folder + \"/*.tif\"))\n",
        "\n",
        "# Load training and dalidation Data\n",
        "X_train, y_train = load_data(train_image_paths, train_mask_paths, target_size=(256, 256))\n",
        "X_val, y_val = load_data(validation_image_paths, validation_mask_paths, target_size=(256, 256))\n",
        "\n",
        "# Augmenting data for training to make the dataset less simple\n",
        "data_gen_args = dict(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "# Create the training generator\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=8)\n",
        "\n",
        "# Training the model with augmentation\n",
        "model = unet_model(input_size=(256, 256, 4))\n",
        "model.fit(train_generator, validation_data=(X_val, y_val), epochs=5, verbose=1)\n",
        "\n",
        "# Saving the model\n",
        "model.save('forest_segmentation_amazon.h5')\n"
      ]
    }
  ]
}